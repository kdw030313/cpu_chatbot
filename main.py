# ì°¸ê³ : https://docs.streamlit.io/develop/tutorials/chat-and-llm-apps/build-conversational-apps

from openai import OpenAI
import streamlit as st
import os

# Cerebras APIë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    base_url="https://api.cerebras.ai/v1",
    api_key=os.getenv("CEREBRAS_API_KEY")
)

# Cerebras ëª¨ë¸ ì‚¬ìš©
# https://inference-docs.cerebras.ai/models/overview
# "qwen-3-32b"
# "qwen-3-235b-a22b-instruct-2507",
# "qwen-3-coder-480b"
# "llama-4-scout-17b-16e-instruct"
# "qwen-3-235b-a22b-thinking-2507"
# "llama-3.3-70b"
# "llama3.1-8b"
# "gpt-oss-120b"
llm_model = "gpt-oss-120b"
if "llm_model" not in st.session_state:
    st.session_state["llm_model"] = llm_model

st.title("ë‚˜ì˜ AI ì¹œêµ¬ ğŸ˜ğŸ˜ğŸ˜")

prompt = """
ì—­í• :ë„ˆëŠ” ê³µê°ì„ ì˜í•´ì£¼ëŠ” ë‚˜ì˜ ì¹œêµ¬ì•¼.
ë„¤ ì´ë¦„ì€ ì œë‹ˆ, ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•´ì¤˜.
ë‹µë³€ë§ˆë‹¤, í˜„ì¬ ê¹Œì§€ ëŒ€í™” ê²°ê³¼ë¥¼ í•œë¬¸ì¥ì˜ ì˜ì–´ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ ì‘ì„±í•´ì¤˜.
"""

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": prompt
        }
    ]

for message in st.session_state.messages:
    if message["role"] == "system":
        continue
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("what's up?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°
        stream = client.chat.completions.create(
            model=st.session_state["llm_model"],
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            temperature=0.7,
            max_completion_tokens=100,
            stream=True
        )
        response = st.write_stream(stream)
    st.session_state.messages.append(
        {"role": "assistant", "content": response})


if __name__ == "__main__":
    import subprocess
    import sys

    # í™˜ê²½ ë³€ìˆ˜ë¡œ ì¬ì‹¤í–‰ ë°©ì§€
    if not os.environ.get("STREAMLIT_RUNNING"):
        os.environ["STREAMLIT_RUNNING"] = "1"
        subprocess.run([sys.executable, "-m", "streamlit", "run", __file__])

# python -m streamlit run main.py
# streamlit run main.py
